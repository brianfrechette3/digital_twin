{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Pinecone client, create index, load + chunk docs, upsert docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [01:38<00:00, 98.36s/it]\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Client configuration details\n",
    "pinecone_conn = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "spec = ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "\n",
    "# Manually get existing index names - TODO: Check if method has been added for this, was getting error trying to use .has_index()\n",
    "index_names = [index[\"name\"] for index in pinecone_conn.list_indexes()]\n",
    "\n",
    "# Create new index\n",
    "index_name = \"digital-twin\"\n",
    "if index_name in index_names:\n",
    "    pinecone_conn.delete_index(index_name)\n",
    "\n",
    "pinecone_conn.create_index(\n",
    "    index_name,\n",
    "    dimension=1536,  # Dimensionality of text-embedding-ada-002 (OpenAI)\n",
    "    metric='dotproduct',\n",
    "    spec=spec\n",
    ")\n",
    "\n",
    "# Wait for index to be created\n",
    "while not pinecone_conn.describe_index(index_name).status[\"ready\"]:\n",
    "    time.sleep(1)\n",
    "\n",
    "# Load all input docs into memory\n",
    "loader = DirectoryLoader(\n",
    "    \"/Users/brianfrechette/Library/Mobile Documents/com~apple~CloudDocs/dev/digital_twin/doc_inputs\",\n",
    "    glob=\"*.docx\",\n",
    "    show_progress=True\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Chunk documents before upserting\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs_chunked = text_splitter.split_documents(docs)\n",
    "\n",
    "# Initialize pinecone vector store by adding chunked docs to the index\n",
    "vector_store = PineconeVectorStore.from_documents(\n",
    "    docs_chunked,\n",
    "    index_name=index_name,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional static context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['425692e4-aadf-4dcc-80a1-b532aac9798d',\n",
       " '10465005-a6fb-4518-abb3-5120ebccec8e',\n",
       " '1eaaca05-ae74-4e06-a0cd-e16aafa71513']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In the future, build crawlers to do this for me from LinkedIn, my personal site, etc.\n",
    "# Manually create documents with static content\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"I have career interests in software development, big data, and machine learning.\",\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"I am specifically interested in working in the tech or finance industry as a software engineer, data engineer, machine learning engineer, or the equivalent.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"I have completed my bachelors of science in engineering from UConn, my master in computer information technology (MCIT) from UPenn, and I plan to start my master of science in aritificial intelligence (MSE-AI) from UPenn beginning in 2025.\",\n",
    "        metadata={\"description\": \"education\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create unique ids, upsert docs\n",
    "uuids = [str(uuid4()) for _ in range(len(docs))]\n",
    "vector_store.add_documents(\n",
    "    documents=docs,\n",
    "    ids=uuids\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9eadad9978e1a81f97c233dbdb8845ad19aeb63b6851879d2b13cc93bce333c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
